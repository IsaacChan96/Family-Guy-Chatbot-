{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "import random\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "import numpy as np\n",
    "import warnings\n",
    "article = Article('http://www.hogwartsishere.com/library/book/7107/chapter/1/')\n",
    "article.download()\n",
    "article.parse()\n",
    "article.nlp()\n",
    "script = article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "def read_file(filepath):\n",
    "    \n",
    "    with open(filepath) as f:\n",
    "        str_text = f.read()\n",
    "    \n",
    "    return str_text\n",
    "spacy=spacy.load('en',disable=['parser', 'tagger','ner'])\n",
    "spacy.max_length = 1500000  \n",
    "tokens=[token.text.lower() for token in spacy(script) if token.text not in '-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n']\n",
    "tokens=[word for word in tokens if word[0]!='\\\\']\n",
    "tokens=[word for word in tokens if word!='\\n\\n']\n",
    "sentence=''\n",
    "store=[]\n",
    "for letter in script:\n",
    "    sentence=sentence+letter\n",
    "    if letter=='.':\n",
    "        store.append(len(sentence.split()))\n",
    "        sentence=\"\"\n",
    "average_sentence=np.floor(sum(store)/len(store))\n",
    "train_len=int(average_sentence+1) # length of setence you want to keep \n",
    "text_sequences=[]\n",
    "for i in range(train_len,len(tokens)):\n",
    "    seq=tokens[i-train_len:i]\n",
    "    text_sequences.append(seq)\n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(text_sequences)\n",
    "sequences=tokenizer.texts_to_sequences(text_sequences)\n",
    "vocabulary_size=len(tokenizer.word_counts)\n",
    "sequences=np.array(sequences)\n",
    "X=sequences[:,:-1]\n",
    "y=sequences[:,-1]\n",
    "y=to_categorical(y,num_classes=vocabulary_size+1)\n",
    "seq_len = X.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size+1, 25, input_length=seq_len))\n",
    "model.add(LSTM(150, return_sequences=True))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(vocabulary_size+1, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "model.fit(X, y, batch_size=64, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select conversations within the script and create new conversations based on number of words supplied\n",
    "\n",
    "def generate(seed_text,num_gen_words): \n",
    "    output_text=[]\n",
    "    input_text=seed_text\n",
    "    for i in range(num_gen_words):\n",
    "        encoded_text=tokenizer.texts_to_sequences([input_text])[0]\n",
    "        pad_encoded=pad_sequences([encoded_text],maxlen=seq_len,truncating='pre')\n",
    "        pred_word_ind=model.predict_classes(pad_encoded,verbose=0)[0]\n",
    "        pred_word=tokenizer.index_word[pred_word_ind]\n",
    "        input_text+=' '+pred_word\n",
    "        output_text.append(pred_word)\n",
    "    return \" \".join(output_text)\n",
    "import random\n",
    "random_pick = random.randint(0,len(text_sequences))\n",
    "random_seed_text=text_sequences[random_pick]\n",
    "seed_text=\" \".join(random_seed_text)\n",
    "generate(seed_text,num_gen_words=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
